{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ JSON saved to: /home/aiml/johnson/Scenario/Scenario_Latest_for_cu_testing/input_data/conf/187_cu_gnb_Active_gNBs_segments.json\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "import json\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "def cu_conf_to_json(conf_path, output_json_path):\n",
        "    with open(conf_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    result = []\n",
        "    assign_pattern = re.compile(r'^\\s*([A-Za-z0-9_]+)\\s*=\\s*(.+?);\\s*(#.*)?$')\n",
        "\n",
        "    for line in lines:\n",
        "        stripped = line.strip()\n",
        "        if stripped.startswith(\"#\") or not stripped:\n",
        "            continue  # Skip comment or empty lines\n",
        "\n",
        "        match = assign_pattern.match(stripped)\n",
        "        if match:\n",
        "            key = match.group(1)\n",
        "            value = match.group(2).strip()\n",
        "            full_content = f\"{key} = {value};\"\n",
        "            result.append({\n",
        "                \"label\": key,\n",
        "                \"content\": full_content\n",
        "            })\n",
        "\n",
        "    with open(output_json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"‚úÖ JSON saved to: {output_json_path}\")\n",
        "\n",
        "def parse_llm_response(response_text):\n",
        "    # Try markdown-wrapped JSON first\n",
        "    match = re.search(r\"```json\\s*(\\[\\s*{.*?}\\s*\\])\\s*```\", response_text, re.DOTALL)\n",
        "    if not match:\n",
        "        # Fallback: Try raw array in text\n",
        "        match = re.search(r\"(\\[\\s*{.*?}\\s*\\])\", response_text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        try:\n",
        "            return json.loads(match.group(1))\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(\"‚ùå JSON decode error:\", e)\n",
        "            return []\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No JSON block found in LLM response.\")\n",
        "        return []\n",
        "\n",
        "base_dir = Path().resolve()\n",
        "\n",
        "cu_input_index = \"test\"\n",
        "\n",
        "# ÊåáÂÆö log Ê™îÊ°à\n",
        "# du_log_file = \"/home/aiml/johnson/Scenario/Scenario_For_testing/DU/log/du.log\"\n",
        "# ru_log_file = \"/home/aiml/johnson/Scenario/Scenario_For_testing/RU/log/RU.log\"\n",
        "\n",
        "# pcap_path = \"/home/aiml/johnson/Scenario/Scenario_For_testing/FH/fh.pcap\"\n",
        "debug_yaml_path = base_dir / \"reference_data\" / \"debug.yaml\"\n",
        "reference_context_path = base_dir / \"reference_data\" / \"reference_config.txt\"\n",
        "# -----------------------\n",
        "\n",
        "\n",
        "cu_log_file = base_dir / \"input_data\"/ \"log\" / f\"{cu_input_index}_log.txt\"\n",
        "current_cu_config_path = base_dir / \"input_data\" / \"conf\"/ f\"{cu_input_index}.conf\"\n",
        "current_cu_config_json_path = current_cu_config_path.with_name(\n",
        "    current_cu_config_path.stem + \"_segments.json\"\n",
        ")\n",
        "cu_conf_to_json(current_cu_config_path, current_cu_config_json_path)\n",
        "\n",
        "rag_after_cu_conf_path = base_dir / \"output_data\" / f\"{cu_input_index}_modification.conf\"\n",
        "rag_after_cu_json_path = base_dir / \"output_data\" / f\"{cu_input_index}_modification.conf.segments.json\"\n",
        "diff_log_path = base_dir / \"output_data\" / f\"{cu_input_index}_diff.log\"\n",
        "\n",
        "\n",
        "\n",
        "# current_du_config_path=\"/home/aiml/johnson/Scenario/Scenario_For_testing/DU/conf/du.conf\"\n",
        "# rag_after_du_conf_path=\"/home/aiml/johnson/Scenario/Scenario_For_testing/DU/conf/Scenario_For_testing_du_modification_1.conf\"\n",
        "# rag_after_du_json_path=\"/home/aiml/johnson/Scenario/Scenario_For_testing/DU/conf/Scenario_For_testing_du_modification_1.conf.segments.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1781286/321401177.py:25: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
            "2025-06-04 00:57:56.365503: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-04 00:57:56.384472: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-06-04 00:57:56.384492: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-06-04 00:57:56.384997: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-04 00:57:56.388484: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-06-04 00:57:56.762558: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Debug embedding Âª∫Á´ãÂÆåÊàê‰∏¶Â∑≤ÂÑ≤Â≠ò\n",
            "üì¶ Á∏ΩÁ≠ÜÊï∏Ôºö 29\n",
            "\n",
            "--- Entry 1 ---\n",
            "Document ID: 9c539bbb-640d-481d-aa12-a4d5c206d125\n",
            "Document Text: Stage: du_cell_config\n",
            "Symptom: Assertion failed due to mismatch between 'active_gNBs' and gNB name in parameter array\n",
            "Log: Assertion (strcmp(GNBSParams[1].strlistptr[0], *GNBParamList.paramarray[0][2].strptr) == 0) failed!\n",
            "\n",
            "Metadata: {'notes': '', 'related_config': 'active_gNBs', 'stage': 'du_cell_config', 'symptom': \"Assertion failed due to mismatch between 'active_gNBs' and gNB name in parameter array\"}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1781286/321401177.py:32: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vectordb.persist()\n"
          ]
        }
      ],
      "source": [
        "with open(debug_yaml_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    debug_data = yaml.safe_load(f)\n",
        "\n",
        "# The embedding format for each entry (based on symptom and log as the primary content)\n",
        "embedding_docs = []\n",
        "for item in debug_data:\n",
        "    content = f\"Stage: {item['stage']}\\nSymptom: {item['symptom']}\\nLog: {item['log_snippet']}\\n\"\n",
        "\n",
        "    if \"notes\" in item and item[\"notes\"]:\n",
        "        content += f\"Notes: {item['notes']}\\n\"\n",
        "\n",
        "    related_config_str = \", \".join(item[\"related_config\"])  # ‚úÖ Convert list to comma-separated string\n",
        "    metadata = {\n",
        "        \"stage\": item[\"stage\"],\n",
        "        \"symptom\": item[\"symptom\"],\n",
        "        \"related_config\": related_config_str,\n",
        "        \"notes\": item.get(\"notes\", \"\") \n",
        "\n",
        "    }\n",
        "    embedding_docs.append({\"content\": content, \"metadata\": metadata})\n",
        "\n",
        "# pprint.pprint(embedding_docs) #for checking\n",
        "\n",
        "# ‰Ω†‰πüÂèØ‰ª•ÊîπÁî® Gemini Êàñ OpenAI embedding\n",
        "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Â∞áÊñáÊú¨ÂµåÂÖ•ÂêëÈáè‰∏¶Â≠òÂÖ• Chroma Ë≥áÊñôÂ∫´\n",
        "texts = [d[\"content\"] for d in embedding_docs]\n",
        "metadatas = [d[\"metadata\"] for d in embedding_docs]\n",
        "\n",
        "vectordb = Chroma.from_texts(texts, embedding=embedding, metadatas=metadatas, persist_directory=\"./error_db\")\n",
        "vectordb.persist()\n",
        "\n",
        "print(\"‚úÖ Debug embedding Âª∫Á´ãÂÆåÊàê‰∏¶Â∑≤ÂÑ≤Â≠ò\")\n",
        "\n",
        "\n",
        "\n",
        "# Ê™¢Êü•ÂµåÂÖ•Á∏ΩÁ≠ÜÊï∏\n",
        "print(\"üì¶ Á∏ΩÁ≠ÜÊï∏Ôºö\", vectordb._collection.count())\n",
        "# È°ØÁ§∫ÂâçÂπæÁ≠ÜÂµåÂÖ•Ë≥áÊñôÂÖßÂÆπÔºàÂåÖÊã¨ÂéüÂßãÊñáÊú¨Ëàá metadataÔºâ\n",
        "peek_data = vectordb._collection.get(limit=1)\n",
        "\n",
        "for i in range(len(peek_data[\"documents\"])):\n",
        "    print(f\"\\n--- Entry {i+1} ---\")\n",
        "    print(\"Document ID:\", peek_data[\"ids\"][i])\n",
        "    print(\"Document Text:\", peek_data[\"documents\"][i])\n",
        "    print(\"Metadata:\", peek_data[\"metadatas\"][i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check CU log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found matching log for stage [cu_config_parsing]: syntax error\n",
            "‚úÖ Found matching log for stage [cu_config_parsing]: syntax error\n",
            "‚úÖ Found matching log for stage [cu_config_parsing]: syntax error\n",
            "‚úÖ Found matching log for stage [cu_config_parsing]: config module \"libconfig\" couldn't be loaded\n",
            "‚úÖ Found matching log for stage [cu_config_parsing]: couldn't be loaded\n",
            "‚úÖ Found matching log for stage [cu_config_parsing]: not properly initialized\n",
            "‚úÖ Found matching log for stage [cu_config_parsing]: init aborted, configuration couldn't be performed\n",
            "‚úÖ Found matching log for stage [cu_config_parsing]: init aborted\n",
            "‚úÖ Found matching log for stage [cu_config_parsing]: not properly initialized\n",
            "‚úÖ Found matching log for stage [cu_config_parsing]: not properly initialized\n",
            "‚úÖ Found matching log for stage [cu_config_parsing]: Getting configuration failed\n",
            "‚úÖ Found matching log for stage [cu_config_parsing]: Getting configuration failed\n",
            "‚úÖ Found matching log for stage [cu_config_parsing]: config_libconfig_init returned -1\n",
            "‚úÖ Found matching log for stage [cu_config_parsing]: config_libconfig_init returned -1\n"
          ]
        }
      ],
      "source": [
        "def clean_text(s):\n",
        "    \"\"\"ÂéªÈô§ANSIÊéßÂà∂Â≠óÂÖÉ + ÁßªÈô§ÂºïËôü + ÂéªÈô§Â§öÈ§òÁ©∫Ê†º\"\"\"\n",
        "    ansi_escape = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])')\n",
        "    s = ansi_escape.sub('', s)\n",
        "    s = s.replace(\"'\", \"\").replace('\"', \"\")\n",
        "    s = s.strip()\n",
        "    return s\n",
        "\n",
        "if not Path(cu_log_file).exists():\n",
        "    raise FileNotFoundError(f\"Log file not found: {cu_log_file}\")\n",
        "if not Path(debug_yaml_path).exists():\n",
        "    raise FileNotFoundError(f\"Debug YAML not found: {debug_yaml_path}\")\n",
        "\n",
        "# Read debug.yaml\n",
        "with open(debug_yaml_path, 'r', encoding='utf-8') as f:\n",
        "    debug_data = yaml.safe_load(f)\n",
        "\n",
        "# Organize (log_snippet, stage) pairs\n",
        "target_entries = []\n",
        "found_results = []\n",
        "found_set = set()\n",
        "all_lines = []\n",
        "\n",
        "\n",
        "for item in debug_data:\n",
        "    if 'log_snippet' in item:\n",
        "        raw_snippet = item['log_snippet']\n",
        "        stage = item.get('stage', 'unknown')\n",
        "\n",
        "        # Â¶ÇÊûúÊòØ listÔºàÂ§öÂÄã snippetÔºâ\n",
        "        if isinstance(raw_snippet, list):\n",
        "            for s in raw_snippet:\n",
        "                target_entries.append((s.strip(), stage))\n",
        "        # Â¶ÇÊûúÊòØÂ≠ó‰∏≤‰∏îÂåÖÂê´ÂàÜËôüÔºàÂ§öÊÆµ snippetÔºâ\n",
        "        elif isinstance(raw_snippet, str) and \";\" in raw_snippet:\n",
        "            parts = [s.strip() for s in raw_snippet.split(\";\")]\n",
        "            for p in parts:\n",
        "                target_entries.append((p, stage))\n",
        "        # ÂñÆ‰∏ÄÂ≠ó‰∏≤ snippet\n",
        "        elif isinstance(raw_snippet, str):\n",
        "            target_entries.append((raw_snippet.strip(), stage))\n",
        "\n",
        "\n",
        "assert_exit_found = False\n",
        "\n",
        "# ÊêúÁ¥¢ log\n",
        "with open(cu_log_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "    for raw_line in f:\n",
        "        line = clean_text(raw_line)\n",
        "        all_lines.append(line)  # Êö´Â≠òÊâÄÊúâ log Ë°åÔºå‰æõÂæåÁ∫åÁº∫Â§±Âà§Êñ∑Áî®\n",
        "\n",
        "        # ÂÖàÊ™¢Êü•ÊòØÂê¶Êúâ Assert_Exit_ Ë®äÊÅØ\n",
        "        if 'Assert_Exit_' in line:\n",
        "            print(f\"‚ö†Ô∏è Found Assert_Exit_ log, skipping critical log check.\")\n",
        "            break  # ÊâæÂà∞ Assert_Exit_ ÊôÇÔºåË∑≥Âá∫Ê™¢Êü•Ôºà‰∏çÂÜçÂü∑Ë°åÈóúÈçµ log Ê™¢Êü•Ôºâ\n",
        "\n",
        "        # ÊØîÂ∞ç debug.yaml ‰∏≠ÁöÑ snippet Ëàá log\n",
        "        for snippet, stage in target_entries:\n",
        "            snippet_cleaned = clean_text(snippet)\n",
        "            if snippet_cleaned in line:\n",
        "                found_results.append((stage, snippet))\n",
        "                found_set.add(snippet_cleaned)\n",
        "                \n",
        "# Ëº∏Âá∫ÁµêÊûú\n",
        "if found_results:\n",
        "    for stage, snippet in found_results:\n",
        "        print(f\"‚úÖ Found matching log for stage [{stage}]: {snippet}\")\n",
        "        query = snippet\n",
        "else:\n",
        "    print(\"‚ùå No matching logs found.\")\n",
        "    query = None\n",
        "\n",
        "success_keywords = [\n",
        "    \"Received NGSetupResponse from AMF\",\n",
        "    \"Received NGAP_REGISTER_GNB_CNF\"\n",
        "]\n",
        "\n",
        "if any(any(kw in line for kw in success_keywords) for line in all_lines):\n",
        "    print(\"‚úÖ CU initialization successful\")\n",
        "    print(\"üü¢ No configuration issue detected, no correction needed.\")\n",
        "    query = \"CU initialization success\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üõë Detected syntax error in config:\n",
            "üìÑ File: /home/aiml/johnson/Scenario/Scenario_Latest/test_data/conf/35_cu_gnb_Num_Threads_PUSCH.conf\n",
            "üìç Line 5: Num_Threads_PUSCH = asdasfsad;\n",
            "Syntax error in 35_cu_gnb_Num_Threads_PUSCH.conf at line 5: Num_Threads_PUSCH = asdasfsad;\n"
          ]
        }
      ],
      "source": [
        "syntax_error_pattern = re.compile(r'\\[LIBCONFIG\\] file (?P<filepath>.+?) - line (?P<linenum>\\d+): syntax error')\n",
        "\n",
        "def clean_text(s):\n",
        "    \"\"\"ÂéªÈô§ANSIÊéßÂà∂Â≠óÂÖÉ + ÁßªÈô§ÂºïËôü + ÂéªÈô§Â§öÈ§òÁ©∫Ê†º\"\"\"\n",
        "    ansi_escape = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])')\n",
        "    s = ansi_escape.sub('', s)\n",
        "    s = s.replace(\"'\", \"\").replace('\"', \"\")\n",
        "    s = s.strip()\n",
        "    return s\n",
        "\n",
        "if not Path(cu_log_file).exists():\n",
        "    raise FileNotFoundError(f\"Log file not found: {cu_log_file}\")\n",
        "if not Path(debug_yaml_path).exists():\n",
        "    raise FileNotFoundError(f\"Debug YAML not found: {debug_yaml_path}\")\n",
        "\n",
        "# Read debug.yaml\n",
        "with open(debug_yaml_path, 'r', encoding='utf-8') as f:\n",
        "    debug_data = yaml.safe_load(f)\n",
        "\n",
        "# Organize (log_snippet, stage) pairs\n",
        "target_entries = []\n",
        "found_results = []\n",
        "found_set = set()\n",
        "all_lines = []\n",
        "\n",
        "\n",
        "for item in debug_data:\n",
        "    if 'log_snippet' in item:\n",
        "        raw_snippet = item['log_snippet']\n",
        "        stage = item.get('stage', 'unknown')\n",
        "\n",
        "        # Â¶ÇÊûúÊòØ listÔºàÂ§öÂÄã snippetÔºâ\n",
        "        if isinstance(raw_snippet, list):\n",
        "            for s in raw_snippet:\n",
        "                target_entries.append((s.strip(), stage))\n",
        "        # Â¶ÇÊûúÊòØÂ≠ó‰∏≤‰∏îÂåÖÂê´ÂàÜËôüÔºàÂ§öÊÆµ snippetÔºâ\n",
        "        elif isinstance(raw_snippet, str) and \";\" in raw_snippet:\n",
        "            parts = [s.strip() for s in raw_snippet.split(\";\")]\n",
        "            for p in parts:\n",
        "                target_entries.append((p, stage))\n",
        "        # ÂñÆ‰∏ÄÂ≠ó‰∏≤ snippet\n",
        "        elif isinstance(raw_snippet, str):\n",
        "            target_entries.append((raw_snippet.strip(), stage))\n",
        "\n",
        "\n",
        "assert_exit_found = False\n",
        "\n",
        "# ÊêúÁ¥¢ log\n",
        "with open(cu_log_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "    for raw_line in f:\n",
        "        line = clean_text(raw_line)\n",
        "        all_lines.append(line)  # Êö´Â≠òÊâÄÊúâ log Ë°åÔºå‰æõÂæåÁ∫åÁº∫Â§±Âà§Êñ∑Áî®\n",
        "\n",
        "        # ‚úÖ Â¶ÇÊûúÂÅµÊ∏¨Âà∞ syntax error ‰∏¶Ëº∏Âá∫ÈåØË™§Ë°å\n",
        "        match = syntax_error_pattern.search(line)\n",
        "        if match:\n",
        "            conf_path_str = match.group(\"filepath\")\n",
        "            line_num = int(match.group(\"linenum\"))\n",
        "\n",
        "            filename = Path(conf_path_str).name\n",
        "            conf_path = current_cu_config_path.parent / filename  # Âà©Áî®Â∑≤Áü• config Ë≥áÊñôÂ§æ\n",
        "\n",
        "            if conf_path.exists():\n",
        "                try:\n",
        "                    with open(conf_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as cf:\n",
        "                        lines = cf.readlines()\n",
        "                        if 0 < line_num <= len(lines):\n",
        "                            error_line = lines[line_num - 1].strip()\n",
        "                        else:\n",
        "                            error_line = \"<Line number out of range>\"\n",
        "                        print(f\"\\nüõë Detected syntax error in config:\")\n",
        "                        print(f\"üìÑ File: {conf_path}\")\n",
        "                        print(f\"üìç Line {line_num}: {error_line}\")\n",
        "                        query = f\"Syntax error in {filename} at line {line_num}: {error_line}\"\n",
        "                        print(query)\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Failed to read config file {conf_path}: {e}\")\n",
        "            else:\n",
        "                print(f\"‚ùå Config file not found: {conf_path}\")\n",
        "            continue  # ÂèØ‰ª•ÈÅ∏ÊìáÊòØÂê¶ÁπºÁ∫åËôïÁêÜÂÖ∂‰ªñ log Ë°å\n",
        "        \n",
        "        # ‚úÖ Â¶ÇÊûúÂÅµÊ∏¨Âà∞ Assert_Exit_ ‰∏¶Ëº∏Âá∫ÈåØË™§Ë°å\n",
        "        if 'Assert_Exit_' in line:\n",
        "            print(f\"‚ö†Ô∏è Found Assert_Exit_ log, skipping critical log check.\")\n",
        "            break\n",
        "\n",
        "        # ‚úÖ ÊØîÂ∞ç debug.yaml ‰∏≠ÁöÑ snippet\n",
        "        for snippet, stage in target_entries:\n",
        "            snippet_cleaned = clean_text(snippet)\n",
        "            if snippet_cleaned in line:\n",
        "                found_results.append((stage, snippet))\n",
        "                found_set.add(snippet_cleaned)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Matched Case ---\n",
            "Case: Stage: cu_config_parsing\n",
            "Symptom: CU failed to start due to syntax error in configuration file\n",
            "Log: syntax error\n",
            "Notes: The value for 'Num_Threads_PUSCH' is not a valid integer.\n",
            "Ensure all numeric parameters in the config file are set to valid values.\n",
            "In this case, 'asdasfsad' caused a parsing failure. Recommended value: 4 or 8.\n",
            "\n",
            "\n",
            "==============\n",
            "Symptom: CU failed to start due to syntax error in configuration file\n",
            "Related Config: Num_Threads_PUSCH\n",
            "Notes:,The value for 'Num_Threads_PUSCH' is not a valid integer.\n",
            "Ensure all numeric parameters in the config file are set to valid values.\n",
            "In this case, 'asdasfsad' caused a parsing failure. Recommended value: 4 or 8.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results = vectordb.similarity_search(query, k=2)\n",
        "\n",
        "# for r in results:\n",
        "#     print(\"- Matched:\", r.page_content)\n",
        "#     print(\"- Related config:\", r.metadata[\"related_config\"])\n",
        "#     print(\"-----------------------------------------------\")\n",
        "\n",
        "matched_case = results[0]\n",
        "matched_content = matched_case.page_content\n",
        "\n",
        "matched_symptom = matched_case.metadata.get(\"symptom\", \"\")\n",
        "matched_related_config = matched_case.metadata.get(\"related_config\", \"\")\n",
        "matched_Notes = matched_case.metadata.get(\"notes\", \"\")\n",
        "print(\"\\n--- Matched Case ---\")\n",
        "print(f\"Case: {matched_content}\")\n",
        "print(\"==============\")\n",
        "print(f\"Symptom: {matched_symptom}\")\n",
        "print(f\"Related Config: {matched_related_config}\")\n",
        "print(f\"Notes:,{matched_Notes}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(current_cu_config_json_path, \"r\") as f:\n",
        "    config_cu_segments_context = json.load(f)\n",
        "# with open(current_du_config_json_path, \"r\") as f:\n",
        "#     config_du_segments_context = json.load(f)\n",
        "# with open(current_ru_config_json_path, \"r\") as f:\n",
        "#     config_ru_segments_context = json.load(f)\n",
        "\n",
        "\n",
        "with open(reference_context_path, \"r\") as f:\n",
        "    reference_context = f.read()\n",
        "\n",
        "# RAG prompt_template\n",
        "rag_prompt_template = f\"\"\"\n",
        "You are a 5G network expert. Your job is to revise configuration files based on observed network issues and debug knowledge.\n",
        "\n",
        "Issue Description:\n",
        "\"{query}\"\n",
        "\n",
        "Matching debug knowledge:\n",
        "{matched_case.metadata[\"symptom\"]}\n",
        "{matched_case.metadata[\"notes\"] if matched_case.metadata[\"notes\"] else \"\"}\n",
        "Relevant parameters: {matched_case.metadata[\"related_config\"]}\n",
        "\n",
        "\n",
        "\n",
        "Reference Device Address Table (external reference file):\n",
        "{reference_context}\n",
        "\n",
        "Current CU configuration block:\n",
        "{config_cu_segments_context}\n",
        "\n",
        "\n",
        "Please revise the configuration using correct addresses from the reference. Output only the revised config section.\n",
        "\n",
        "Return a list of JSON objects with the following structure:\n",
        "\n",
        "```json\n",
        "[\n",
        "  {{\n",
        "    \"label\": \"parameter_name\",\n",
        "    \"content\": \"parameter_name = (...);\",\n",
        "    \"reference_reason\": \"Short explanation matching the value to the reference device table (e.g., correct MAC, matches expected setting).\",\n",
        "    \"model_reason\": \"Additional expert analysis in 1-2 sentences explaining why this change is necessary, beneficial, or resolves a network issue.\"\n",
        "    \"target\": \"CU\" or \"DU\" or \"RU\" or \"FH\"\n",
        "  }},\n",
        "  ...\n",
        "]\n",
        "```\n",
        "\n",
        "- Only include parameters listed in 'Relevant parameters'.\n",
        "- Do not include any explanation outside of the JSON structure.\n",
        "- Keep \"reference_reason\" based on the reference table.\n",
        "- Derive \"model_reason\" from your own technical reasoning.\n",
        "- Set the \"target\" field based on the location of the parameter: \"CU\" for CU config, \"DU\" for DU config, \"RU\" for RU config, and \"FH\" for FH config.\n",
        "- If multiple configuration problems exist at the same time, return multiple JSON objects ‚Äî one for each necessary change.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "none_rag_prompt_template = f\"\"\"\n",
        "You are a 5G network expert. Your job is to revise configuration files based on observed network issues.\n",
        "\n",
        "Issue Description:\n",
        "\"{query}\"\n",
        "\n",
        "Current configuration block:\n",
        "{config_cu_segments_context}\n",
        "\n",
        "Please revise the configuration to resolve the described issue based on your technical expertise.\n",
        "\n",
        "Return a list of JSON objects with the following structure:\n",
        "\n",
        "```json\n",
        "[\n",
        "  {{\n",
        "    \"label\": \"parameter_name\",\n",
        "    \"content\": \"parameter_name = (...);\",\n",
        "    \"model_reason\": \"Technical explanation in 1-2 sentences explaining why this change is necessary, beneficial, or resolves the network issue.\"\n",
        "  }},\n",
        "  ...\n",
        "]\n",
        "```\n",
        "\n",
        "- Only revise parameters that are necessary to resolve the issue.\n",
        "- If no changes are needed, return an empty list: []\n",
        "- Strictly output only valid JSON without any additional text or explanation.\n",
        "\"\"\"\n",
        "import os\n",
        "reason_output_dir = \"Reason\"\n",
        "os.makedirs(reason_output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "def save_json(filename, data):\n",
        "    with open(os.path.join(reason_output_dir, filename), \"w\", encoding='utf-8') as f:\n",
        "        json.dump(data, f, indent=2, ensure_ascii=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM Suggested RevisionsÔºö\n",
            "\n",
            "RAG Response:\n",
            " ```json\n",
            "[\n",
            "  {\n",
            "    \"label\": \"Num_Threads_PUSCH\",\n",
            "    \"content\": \"Num_Threads_PUSCH = 4;\",\n",
            "    \"reference_reason\": \"No direct reference, using recommended value.\",\n",
            "    \"model_reason\": \"The value for 'Num_Threads_PUSCH' must be a valid integer to resolve the syntax error and ensure proper CU functionality. A value of 4 is recommended for optimal performance.\",\n",
            "    \"target\": \"CU\"\n",
            "  }\n",
            "]\n",
            "```\n",
            "========= Suggestions =========\n",
            "[{'label': 'Num_Threads_PUSCH', 'content': 'Num_Threads_PUSCH = 4;', 'reference_reason': 'No direct reference, using recommended value.', 'model_reason': \"The value for 'Num_Threads_PUSCH' must be a valid integer to resolve the syntax error and ensure proper CU functionality. A value of 4 is recommended for optimal performance.\", 'target': 'CU'}]\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "  api_key = \"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\"\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"meta/llama-3.3-70b-instruct\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": rag_prompt_template}\n",
        "    ],\n",
        "    temperature=0.2,\n",
        "    top_p=0.7,\n",
        "    max_tokens=1024,\n",
        "    stream=False\n",
        ")\n",
        "rag_response_text = response.choices[0].message.content\n",
        "print(\"LLM Suggested RevisionsÔºö\\n\")\n",
        "print(\"RAG Response:\\n\", rag_response_text)\n",
        "\n",
        "\n",
        "rag_llm_suggestions = parse_llm_response(rag_response_text)\n",
        "print(\"========= Suggestions =========\")\n",
        "print(rag_llm_suggestions)\n",
        "\n",
        "\n",
        "\n",
        "save_json(f\"{matched_related_config}_rag.json\", rag_llm_suggestions)\n",
        "# save_json(f\"{matched_related_config}_none_rag.json\", none_rag_llm_suggestions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# genai.configure(api_key=\"AIzaSyBqqRkGvIkAJUZ5MgYcvxw4t3Lx12D4rWU\") #set your API key here\n",
        "# model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "# rag_response = model.generate_content(rag_prompt_template)                                # Gemini API\n",
        "# # LLM Suggested Revisions\n",
        "# print(\"LLM Suggested RevisionsÔºö\\n\")\n",
        "# print(rag_response.text)\n",
        "\n",
        "# rag_llm_suggestions = parse_llm_response(rag_response.text)\n",
        "# print(\"========= Suggestions =========\")\n",
        "# print(rag_llm_suggestions)\n",
        "\n",
        "\n",
        "\n",
        "# save_json(f\"{matched_related_config}_rag.json\", rag_llm_suggestions)\n",
        "# # save_json(f\"{matched_related_config}_none_rag.json\", none_rag_llm_suggestions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import difflib\n",
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "def safe_print(text):\n",
        "    try:\n",
        "        print(text.encode('utf-8', 'replace').decode('utf-8'))\n",
        "    except Exception:\n",
        "        print(\"[Output error suppressed]\")\n",
        "\n",
        "\n",
        "\n",
        "def compare_conf_files(file1, file2, output_path):\n",
        "    file1 = str(file1)\n",
        "    file2 = str(file2)\n",
        "    output_path = str(output_path)\n",
        "\n",
        "    with open(file1, 'r', encoding='utf-8') as f1, open(file2, 'r', encoding='utf-8') as f2:\n",
        "        lines1 = f1.readlines()\n",
        "        lines2 = f2.readlines()\n",
        "\n",
        "    diff = difflib.unified_diff(\n",
        "        lines1, lines2,\n",
        "        fromfile=file1,\n",
        "        tofile=file2,\n",
        "        lineterm=''\n",
        "    )\n",
        "\n",
        "    modified_lines = [\n",
        "        line for line in diff\n",
        "        if (line.startswith('+') or line.startswith('-')) and not line.startswith('+++') and not line.startswith('---')\n",
        "    ]\n",
        "\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(modified_lines))\n",
        "\n",
        "    print(f\"‚úÖ Diff saved to: {output_path}\")\n",
        "\n",
        "\n",
        "def apply_llm_suggestions(conf_path, output_path, llm_suggestions, config_type):\n",
        "    with open(conf_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    modified_labels = []\n",
        "    change_log = []\n",
        "\n",
        "    for suggestion in llm_suggestions:\n",
        "        label = suggestion[\"label\"]\n",
        "        replacement = suggestion[\"content\"]\n",
        "        model_reason = suggestion.get(\"model_reason\", \"\")\n",
        "\n",
        "        pattern = rf\"{label}\\s*=\\s*.*?;\"\n",
        "        match = re.search(pattern, content, flags=re.DOTALL)\n",
        "\n",
        "        if match:\n",
        "            original_line = match.group(0).strip()\n",
        "            if original_line != replacement.strip():\n",
        "                content = re.sub(pattern, replacement, content, flags=re.DOTALL)\n",
        "                modified_labels.append(label)\n",
        "                change_log.append((label, original_line, replacement.strip(), model_reason))\n",
        "            else:\n",
        "                safe_print(f\"‚ÑπÔ∏è [{config_type}] {label} already matches suggested value.\")\n",
        "        else:\n",
        "            safe_print(f\"‚ö†Ô∏è [{config_type}] No matching setting found: {label}\")\n",
        "\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "    safe_print(f\"‚úÖ [{config_type}] Updated file: {output_path}\")\n",
        "\n",
        "    if modified_labels:\n",
        "        safe_print(f\"üõ†Ô∏è [{config_type}] Modified parameters:\")\n",
        "        for label in modified_labels:\n",
        "            safe_print(f\" - {label}\")\n",
        "    else:\n",
        "        safe_print(f\"üì≠ [{config_type}] No parameters were modified\")\n",
        "\n",
        "    return content, modified_labels, change_log\n",
        "\n",
        "\n",
        "def split_suggestions_by_target(llm_suggestions):\n",
        "    cu_suggestions = []\n",
        "    du_suggestions = []\n",
        "    for s in llm_suggestions:\n",
        "        if s.get(\"target\") == \"CU\":\n",
        "            cu_suggestions.append(s)\n",
        "        elif s.get(\"target\") == \"DU\":\n",
        "            du_suggestions.append(s)\n",
        "    return cu_suggestions, du_suggestions\n",
        "\n",
        "def save_modified_config(content, output_path, config_type):\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(content)\n",
        "    safe_print(f\"‚úÖ [{config_type}] Updated file: {output_path}\")\n",
        "\n",
        "def save_sft_data(change_log, output_path, config_type, suggestions, current_path):\n",
        "    reason_map = {s[\"label\"]: s.get(\"reference_reason\", \"\") for s in suggestions}\n",
        "    sft_data = []\n",
        "    for label, before, after, model_reason in change_log:\n",
        "        sft_data.append({\n",
        "            \"label\": label,\n",
        "            \"before\": before,\n",
        "            \"after\": after,\n",
        "            \"model_reason\": model_reason,\n",
        "            \"reference_reason\": reason_map.get(label, \"\"),\n",
        "            \"config_type\": config_type,\n",
        "            \"source_file\": os.path.basename(current_path)\n",
        "        })\n",
        "\n",
        "    json_path = os.path.splitext(output_path)[0] + f\"_{config_type}_sft.json\"\n",
        "    with open(json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(sft_data, f, indent=2, ensure_ascii=False)\n",
        "    safe_print(f\"\\nüìÅ [{config_type}] SFT data saved to: {json_path}\")\n",
        "\n",
        "def process_config_type(config_type, suggestions, current_path, modified_path, diff_log_path):\n",
        "    if not suggestions:\n",
        "        safe_print(f\"üìÑ No LLM suggestions for {config_type}.\")\n",
        "        return\n",
        "\n",
        "    content, modified_labels, change_log = apply_llm_suggestions(\n",
        "        conf_path=current_path,\n",
        "        output_path=modified_path,\n",
        "        llm_suggestions=suggestions,\n",
        "        config_type=config_type\n",
        "    )\n",
        "\n",
        "    save_modified_config(content, modified_path, config_type)\n",
        "    compare_conf_files(current_path, modified_path, diff_log_path)\n",
        "    save_sft_data(change_log, modified_path, config_type, suggestions, current_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CU Suggestions:\n",
            "[Output error suppressed]\n",
            "DU Suggestions:\n",
            "[Output error suppressed]\n",
            "‚úÖ [CU] Updated file: /home/aiml/johnson/Scenario/Scenario_Latest/output_data/35_cu_gnb_Num_Threads_PUSCH_modification.conf\n",
            "üõ†Ô∏è [CU] Modified parameters:\n",
            " - Num_Threads_PUSCH\n",
            "‚úÖ [CU] Updated file: /home/aiml/johnson/Scenario/Scenario_Latest/output_data/35_cu_gnb_Num_Threads_PUSCH_modification.conf\n",
            "‚úÖ Diff saved to: /home/aiml/johnson/Scenario/Scenario_Latest/output_data/35_cu_gnb_Num_Threads_PUSCH_diff.log\n",
            "\n",
            "üìÅ [CU] SFT data saved to: /home/aiml/johnson/Scenario/Scenario_Latest/output_data/35_cu_gnb_Num_Threads_PUSCH_modification_CU_sft.json\n"
          ]
        }
      ],
      "source": [
        "cu_suggestions, du_suggestions = split_suggestions_by_target(rag_llm_suggestions)\n",
        "safe_print(\"CU Suggestions:\")\n",
        "safe_print(cu_suggestions)\n",
        "safe_print(\"DU Suggestions:\")\n",
        "safe_print(du_suggestions)\n",
        "\n",
        "process_config_type(\n",
        "    config_type=\"CU\",\n",
        "    suggestions= cu_suggestions,\n",
        "    current_path= current_cu_config_path,\n",
        "    modified_path=rag_after_cu_conf_path,\n",
        "    diff_log_path= diff_log_path\n",
        ")\n",
        "\n",
        "# process_config_type(\n",
        "#     config_type=\"DU\",\n",
        "#     suggestions=du_suggestions,\n",
        "#     current_path=current_du_config_path,\n",
        "#     modified_path=rag_after_du_conf_path,\n",
        "#     diff_log_path=\"/home/aiml/johnson/Scenario/Scenario_For_testing/DU/conf/du_diff_log.txt\"\n",
        "# )\n",
        "\n",
        "# process_config_type(\n",
        "#     config_type=\"RU\",\n",
        "#     suggestions=du_suggestions,\n",
        "#     current_path=current_ru_config_path,\n",
        "#     modified_path=rag_after_ru_conf_path,\n",
        "#     diff_log_path=\"/home/aiml/johnson/Scenario/Scenario_For_testing/DU/conf/du_diff_log.txt\"\n",
        "# )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
