{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… JSON saved to: /home/aiml/johnson/Scenario/Scenario_Latest_for_du_testing/input_data/conf/0_cu_gnb_original_segments.json\n",
            "âœ… JSON saved to /home/aiml/johnson/Scenario/Scenario_Latest_for_du_testing/input_data/conf/97_du_gnb_nr_cellid_v12_segments.json\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "import json\n",
        "\n",
        "def cu_conf_to_json(conf_path, output_json_path):\n",
        "    with open(conf_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    result = []\n",
        "    assign_pattern = re.compile(r'^\\s*([A-Za-z0-9_]+)\\s*=\\s*(.+?);\\s*(#.*)?$')\n",
        "\n",
        "    for line in lines:\n",
        "        stripped = line.strip()\n",
        "        if stripped.startswith(\"#\") or not stripped:\n",
        "            continue  # Skip comment or empty lines\n",
        "\n",
        "        match = assign_pattern.match(stripped)\n",
        "        if match:\n",
        "            key = match.group(1)\n",
        "            value = match.group(2).strip()\n",
        "            full_content = f\"{key} = {value};\"\n",
        "            result.append({\n",
        "                \"label\": key,\n",
        "                \"content\": full_content\n",
        "            })\n",
        "\n",
        "    with open(output_json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"âœ… JSON saved to: {output_json_path}\")\n",
        "def du_conf_to_json(conf_path, output_json_path):\n",
        "    results = []\n",
        "\n",
        "    with open(conf_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        # ç§»é™¤è¨»è§£èˆ‡å‰å¾Œç©ºç™½\n",
        "        line = line.strip()\n",
        "        if not line or line.startswith(\"#\") or line.startswith(\"//\"):\n",
        "            continue\n",
        "\n",
        "        # æ­£è¦åŒ–æŠ“å– label èˆ‡ contentï¼ˆåªæŠ“æœ€å¤–å±¤åƒæ•¸ï¼‰\n",
        "        match = re.match(r'^([a-zA-Z0-9_]+)\\s*=\\s*.+;', line)\n",
        "        if match:\n",
        "            label = match.group(1)\n",
        "            results.append({\n",
        "                \"label\": label,\n",
        "                \"content\": line\n",
        "            })\n",
        "\n",
        "    # å„²å­˜ç‚º JSON\n",
        "    with open(output_json_path, 'w', encoding='utf-8') as outfile:\n",
        "        json.dump(results, outfile, indent=2)\n",
        "    print(f\"âœ… JSON saved to {output_json_path}\")\n",
        "\n",
        "\n",
        "\n",
        "base_dir = Path().resolve()\n",
        "cu_input_index = \"0_cu_gnb_original\"\n",
        "du_input_index = \"97_du_gnb_nr_cellid_v12\"\n",
        "\n",
        "# æŒ‡å®š log æª”æ¡ˆ\n",
        "# du_log_file = \"/home/aiml/johnson/Scenario/Scenario_For_testing/DU/log/du.log\"\n",
        "# ru_log_file = \"/home/aiml/johnson/Scenario/Scenario_For_testing/RU/log/RU.log\"\n",
        "\n",
        "# pcap_path = \"/home/aiml/johnson/Scenario/Scenario_For_testing/FH/fh.pcap\"\n",
        "debug_yaml_path = base_dir / \"reference_data\" / \"debug.yaml\"\n",
        "reference_context_path = base_dir / \"reference_data\" / \"reference_config.txt\"\n",
        "# -----------------------\n",
        "\n",
        "# æŒ‡å®š cu æª”æ¡ˆ\n",
        "cu_log_file = base_dir / \"input_data\"/ \"log\" / f\"{cu_input_index}_log.txt\"\n",
        "current_cu_config_path = base_dir / \"input_data\" / \"conf\"/ f\"{cu_input_index}.conf\"\n",
        "current_cu_config_json_path = current_cu_config_path.with_name(\n",
        "    current_cu_config_path.stem + \"_segments.json\"\n",
        ")\n",
        "cu_conf_to_json(current_cu_config_path, current_cu_config_json_path)\n",
        "rag_after_cu_conf_path = base_dir / \"output_data\" / f\"{cu_input_index}_modification.conf\"\n",
        "rag_after_cu_json_path = base_dir / \"output_data\" / f\"{cu_input_index}_modification.conf.segments.json\"\n",
        "cu_diff_log_path = base_dir / \"output_data\" / f\"{cu_input_index}_diff.log\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# æŒ‡å®š du æª”æ¡ˆ\n",
        "du_log_file = base_dir / \"input_data\"/ \"log\" / f\"{du_input_index}_log.txt\"\n",
        "current_du_config_path = base_dir / \"input_data\" / \"conf\"/ f\"{du_input_index}.conf\"\n",
        "current_du_config_json_path = current_du_config_path.with_name(\n",
        "    current_du_config_path.stem + \"_segments.json\"\n",
        ")\n",
        "du_conf_to_json(current_du_config_path, current_du_config_json_path)\n",
        "rag_after_du_conf_path = base_dir / \"output_data\" / f\"{du_input_index}_modification.conf\"\n",
        "rag_after_du_json_path = base_dir / \"output_data\" / f\"{du_input_index}_modification.conf.segments.json\"\n",
        "du_diff_log_path = base_dir / \"output_data\" / f\"{du_input_index}_diff.log\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# current_du_config_path=\"/home/aiml/johnson/Scenario/Scenario_For_testing/DU/conf/du.conf\"\n",
        "# rag_after_du_conf_path=\"/home/aiml/johnson/Scenario/Scenario_For_testing/DU/conf/Scenario_For_testing_du_modification_1.conf\"\n",
        "# rag_after_du_json_path=\"/home/aiml/johnson/Scenario/Scenario_For_testing/DU/conf/Scenario_For_testing_du_modification_1.conf.segments.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Functions and Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "from pathlib import Path\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import difflib\n",
        "\n",
        "\n",
        "def old_parse_llm_response(response_text):\n",
        "    # Try markdown-wrapped JSON first\n",
        "    match = re.search(r\"```json\\s*(\\[\\s*{.*?}\\s*\\])\\s*```\", response_text, re.DOTALL)\n",
        "    if not match:\n",
        "        # Fallback: Try raw array in text\n",
        "        match = re.search(r\"(\\[\\s*{.*?}\\s*\\])\", response_text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        try:\n",
        "            return json.loads(match.group(1))\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(\"âŒ JSON decode error:\", e)\n",
        "            return []\n",
        "    else:\n",
        "        print(\"âš ï¸ No JSON block found in LLM response.\")\n",
        "        return []\n",
        "\n",
        "def parse_llm_response(response_text):\n",
        "    \"\"\"\n",
        "    Parse LLM JSON array from response text, clean formatting issues and return as Python list.\n",
        "    \"\"\"\n",
        "    # 1. å»é™¤ ```json åŒ…è£¹\n",
        "    response_text = re.sub(r\"```json\\s*\", \"\", response_text)\n",
        "    response_text = re.sub(r\"```\", \"\", response_text)\n",
        "\n",
        "    # 2. å˜—è©¦æ“·å– JSON é™£åˆ—\n",
        "    match = re.search(r\"(\\[\\s*{.*?}\\s*\\])\", response_text, re.DOTALL)\n",
        "    if not match:\n",
        "        print(\"âš ï¸ No JSON block found in LLM response.\")\n",
        "        return []\n",
        "\n",
        "    raw_json = match.group(1)\n",
        "\n",
        "    # 3. ä¿®æ­£å¸¸è¦‹éŒ¯èª¤ï¼šlike `tr_s_preference = ;` â†’ åŠ ä¸Šå¼•è™Ÿ\n",
        "    raw_json = re.sub(r'=\\s*;', '= \"\";', raw_json)\n",
        "\n",
        "    # 4. ä¿®æ­£ content æ¬„ä½ä¸­éŒ¯èª¤ä½¿ç”¨å–®å¼•è™Ÿçš„æƒ…æ³\n",
        "    raw_json = re.sub(r'\"content\":\\s*\\'(.*?)\\'', lambda m: '\"content\": \"{}\"'.format(m.group(1).replace('\"', '\\\\\"')), raw_json)\n",
        "\n",
        "    # 5. å˜—è©¦è§£æ JSON\n",
        "    try:\n",
        "        return json.loads(raw_json)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"âŒ JSON decode error:\", e)\n",
        "        print(\"ğŸ§ª Raw JSON:\\n\", raw_json)\n",
        "        return []\n",
        "    \n",
        "def process_config_type(config_type, suggestions, current_path, modified_path, diff_log_path):\n",
        "    sft_data = []\n",
        "    if not suggestions:\n",
        "        safe_print(f\"ğŸ“„ No LLM suggestions for {config_type}.\")\n",
        "        return\n",
        "\n",
        "    content, modified_labels, change_log = apply_llm_suggestions(\n",
        "        conf_path=current_path,\n",
        "        output_path=modified_path,\n",
        "        llm_suggestions=suggestions,\n",
        "        config_type=config_type\n",
        "    )\n",
        "\n",
        "    save_modified_config(content, modified_path, config_type)\n",
        "    compare_conf_files(current_path, modified_path, diff_log_path)\n",
        "    save_sft_data(change_log, modified_path, config_type, suggestions, current_path)\n",
        "\n",
        "def save_modified_config(content, output_path, config_type):\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(content)\n",
        "    safe_print(f\"âœ… [{config_type}] Updated file: {output_path}\")\n",
        "\n",
        "def compare_conf_files(file1, file2, output_path):\n",
        "    file1 = str(file1)\n",
        "    file2 = str(file2)\n",
        "    output_path = str(output_path)\n",
        "\n",
        "    with open(file1, 'r', encoding='utf-8') as f1, open(file2, 'r', encoding='utf-8') as f2:\n",
        "        lines1 = f1.readlines()\n",
        "        lines2 = f2.readlines()\n",
        "\n",
        "    diff = difflib.unified_diff(\n",
        "        lines1, lines2,\n",
        "        fromfile=file1,\n",
        "        tofile=file2,\n",
        "        lineterm=''\n",
        "    )\n",
        "\n",
        "    modified_lines = [\n",
        "        line for line in diff\n",
        "        if (line.startswith('+') or line.startswith('-')) and not line.startswith('+++') and not line.startswith('---')\n",
        "    ]\n",
        "\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(modified_lines))\n",
        "\n",
        "    print(f\"âœ… Diff saved to: {output_path}\")\n",
        "\n",
        "def save_sft_data(change_log, output_path, config_type, suggestions, current_path):\n",
        "    sft_data = []  # âœ… è£œä¸Šé€™è¡Œ\n",
        "    reason_map = {s[\"label\"]: s.get(\"reference_reason\", \"\") for s in suggestions}\n",
        "    \n",
        "    for label, before, after, model_reason in change_log:\n",
        "        sft_data.append({\n",
        "            \"label\": label,\n",
        "            \"before\": before,\n",
        "            \"after\": after,\n",
        "            \"model_reason\": model_reason,\n",
        "            \"reference_reason\": reason_map.get(label, \"\"),\n",
        "            \"config_type\": config_type,\n",
        "            \"source_file\": os.path.basename(current_path)\n",
        "        })\n",
        "\n",
        "    # âœ… æ­£ç¢ºå„²å­˜ JSON çš„é‚è¼¯ï¼ˆè‡ªå‹•è½‰æˆ _CU_sft.jsonï¼‰\n",
        "    json_path = os.path.splitext(output_path)[0] + f\"_{config_type}_sft.json\"\n",
        "    with open(json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(sft_data, f, indent=2, ensure_ascii=False)\n",
        "    safe_print(f\"\\nğŸ“ [{config_type}] SFT data saved to: {json_path}\")\n",
        "\n",
        "def safe_print(text):\n",
        "    try:\n",
        "        print(text.encode('utf-8', 'replace').decode('utf-8'))\n",
        "    except Exception:\n",
        "        print(\"[Output error suppressed]\")\n",
        "\n",
        "def apply_llm_suggestions(conf_path, output_path, llm_suggestions, config_type):\n",
        "    with open(conf_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    modified_labels = []\n",
        "    change_log = []\n",
        "\n",
        "    for suggestion in llm_suggestions:\n",
        "        label = suggestion[\"label\"]\n",
        "        replacement = suggestion[\"content\"]\n",
        "        model_reason = suggestion.get(\"model_reason\", \"\")\n",
        "\n",
        "        pattern = rf\"{label}\\s*=\\s*.*?;\"\n",
        "        match = re.search(pattern, content, flags=re.DOTALL)\n",
        "\n",
        "        if match:\n",
        "            original_line = match.group(0).strip()\n",
        "            if original_line != replacement.strip():\n",
        "                content = re.sub(pattern, replacement, content, flags=re.DOTALL)\n",
        "                modified_labels.append(label)\n",
        "                change_log.append((label, original_line, replacement.strip(), model_reason))\n",
        "            else:\n",
        "                safe_print(f\"â„¹ï¸ [{config_type}] {label} already matches suggested value.\")\n",
        "        else:\n",
        "            safe_print(f\"âš ï¸ [{config_type}] No matching setting found: {label}\")\n",
        "\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "    safe_print(f\"âœ… [{config_type}] Updated file: {output_path}\")\n",
        "\n",
        "    if modified_labels:\n",
        "        safe_print(f\"ğŸ› ï¸ [{config_type}] Modified parameters:\")\n",
        "        for label in modified_labels:\n",
        "            safe_print(f\" - {label}\")\n",
        "    else:\n",
        "        safe_print(f\"ğŸ“­ [{config_type}] No parameters were modified\")\n",
        "\n",
        "    return content, modified_labels, change_log\n",
        "\n",
        "def split_suggestions_by_target(llm_suggestions):\n",
        "    cu_suggestions = []\n",
        "    du_suggestions = []\n",
        "    for s in llm_suggestions:\n",
        "        if s.get(\"target\") == \"CU\":\n",
        "            cu_suggestions.append(s)\n",
        "        elif s.get(\"target\") == \"DU\":\n",
        "            du_suggestions.append(s)\n",
        "    return cu_suggestions, du_suggestions\n",
        "\n",
        "def clean_text(s):\n",
        "    \"\"\"å»é™¤ANSIæ§åˆ¶å­—å…ƒ + ç§»é™¤å¼•è™Ÿ + å»é™¤å¤šé¤˜ç©ºæ ¼\"\"\"\n",
        "    ansi_escape = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])')\n",
        "    s = ansi_escape.sub('', s)\n",
        "    s = s.replace(\"'\", \"\").replace('\"', \"\")\n",
        "    s = s.strip()\n",
        "    return s\n",
        "\n",
        "def extract_config_key(line: str) -> str:\n",
        "    # ç§»é™¤ BOM, éå¯åˆ—å°ç©ºç™½ç­‰ç‰¹æ®Šç¬¦è™Ÿ\n",
        "    line = line.encode(\"ascii\", errors=\"ignore\").decode().strip()\n",
        "    line = line.split(';')[0]  # ç§»é™¤è¨»è§£æˆ–è¡Œå°¾åˆ†è™Ÿ\n",
        "    match = re.match(r\"(\\w+)\\s*=\", line)\n",
        "    return match.group(1) if match else \"\"\n",
        "\n",
        "def find_case_by_related_config(config_key, vectordb, top_k=3):\n",
        "    results = vectordb.similarity_search(config_key, k=top_k)\n",
        "    return next(\n",
        "        (doc for doc in results if config_key in doc.metadata.get('related_config', [])),\n",
        "        None\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Debug embedding å»ºç«‹å®Œæˆä¸¦å·²å„²å­˜\n",
            "ğŸ“¦ ç¸½ç­†æ•¸ï¼š 688\n",
            "\n",
            "--- Entry 1 ---\n",
            "Document ID: ca20a0dd-9f68-43a6-ab09-957c297fb5a2\n",
            "Document Text: Stage: cu_init_success\n",
            "Symptom: CU initialization success\n",
            "Log: Initialization complete without error\n",
            "Related Config: \n",
            "Notes: The CU started successfully and no issues were detected in the configuration file.\n",
            "All required parameters are correctly set.\n",
            "No changes are required at this stage.\n",
            "\n",
            "Metadata: {'notes': 'The CU started successfully and no issues were detected in the configuration file.\\nAll required parameters are correctly set.\\nNo changes are required at this stage.\\n', 'related_config': '', 'stage': 'cu_init_success', 'symptom': 'CU initialization success', 'type': 'CU'}\n",
            "\n",
            "--- Last Entry ---\n",
            "Document ID: 941792a6-efee-493f-9761-501dcb2249da\n",
            "Document Text: Stage: du_init\n",
            "Symptom: DU crashed due to mismatched nr_cellid with CU\n",
            "Log: ['Assertion (du_cell->nr_cellid == cu_cell->nr_cellid) failed!', 'CellID mismatch: DU 2147483648 vs CU -2147483648', 'f1_setup_response() Exiting OAI softmodem']\n",
            "Related Config: nr_cellid\n",
            "Notes: The DU defines `nr_cellid = 2147483648` (0x80000000), which exceeds the signed 32-bit integer range.\n",
            "\n",
            "When the CU parses this value, it may interpret it as `-2147483648`, causing a mismatch during F1 Setup handling.\n",
            "\n",
            "This triggers an assertion failure and causes the DU softmodem to crash during initialization.\n",
            "\n",
            "-  Fix:\n",
            "- Set `nr_cellid` to a safe and valid positive value like:\n",
            "  ```c\n",
            "  nr_cellid = 1;\n",
            "  ```\n",
            "\n",
            "- Best Practice:\n",
            "- Always ensure both DU and CU explicitly define the same `nr_cellid`.\n",
            "- Avoid borderline values like `2147483648` that may cause signed overflow.\n",
            "\n",
            "Metadata: {'notes': 'The DU defines `nr_cellid = 2147483648` (0x80000000), which exceeds the signed 32-bit integer range.\\n\\nWhen the CU parses this value, it may interpret it as `-2147483648`, causing a mismatch during F1 Setup handling.\\n\\nThis triggers an assertion failure and causes the DU softmodem to crash during initialization.\\n\\n-  Fix:\\n- Set `nr_cellid` to a safe and valid positive value like:\\n  ```c\\n  nr_cellid = 1;\\n  ```\\n\\n- Best Practice:\\n- Always ensure both DU and CU explicitly define the same `nr_cellid`.\\n- Avoid borderline values like `2147483648` that may cause signed overflow.\\n', 'related_config': 'nr_cellid', 'stage': 'du_init', 'symptom': 'DU crashed due to mismatched nr_cellid with CU', 'type': 'DU'}\n"
          ]
        }
      ],
      "source": [
        "with open(debug_yaml_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    debug_data = yaml.safe_load(f)\n",
        "\n",
        "# The embedding format for each entry (based on symptom and log as the primary content)\n",
        "embedding_docs = []\n",
        "for item in debug_data:\n",
        "    related_config_str = \", \".join(item.get(\"related_config\", []))\n",
        "    notes = item.get(\"notes\", \"\")\n",
        "    type_value = item.get(\"type\", \"UNKNOWN\")  \n",
        "\n",
        "    content = (\n",
        "        f\"Stage: {item['stage']}\\n\"\n",
        "        f\"Symptom: {item['symptom']}\\n\"\n",
        "        f\"Log: {item['log_snippet']}\\n\"\n",
        "        f\"Related Config: {related_config_str}\\n\"\n",
        "        f\"Notes: {notes}\"\n",
        "    )\n",
        "    \n",
        "    metadata = {\n",
        "        \"stage\": item[\"stage\"],\n",
        "        \"type\": type_value,        \n",
        "        \"symptom\": item[\"symptom\"],\n",
        "        \"related_config\": related_config_str,\n",
        "        \"notes\": notes,\n",
        "    }\n",
        "\n",
        "    embedding_docs.append({\"content\": content, \"metadata\": metadata})\n",
        "\n",
        "# pprint.pprint(embedding_docs) #for checking\n",
        "\n",
        "# ä½ ä¹Ÿå¯ä»¥æ”¹ç”¨ Gemini æˆ– OpenAI embedding\n",
        "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# å°‡æ–‡æœ¬åµŒå…¥å‘é‡ä¸¦å­˜å…¥ Chroma è³‡æ–™åº«\n",
        "texts = [d[\"content\"] for d in embedding_docs]\n",
        "metadatas = [d[\"metadata\"] for d in embedding_docs]\n",
        "\n",
        "vectordb = Chroma.from_texts(texts, embedding=embedding, metadatas=metadatas, persist_directory=\"./error_db\")\n",
        "vectordb.persist()\n",
        "\n",
        "print(\"âœ… Debug embedding å»ºç«‹å®Œæˆä¸¦å·²å„²å­˜\")\n",
        "\n",
        "\n",
        "\n",
        "# æª¢æŸ¥åµŒå…¥ç¸½ç­†æ•¸\n",
        "print(\"ğŸ“¦ ç¸½ç­†æ•¸ï¼š\", vectordb._collection.count())\n",
        "# é¡¯ç¤ºå‰å¹¾ç­†åµŒå…¥è³‡æ–™å…§å®¹ï¼ˆåŒ…æ‹¬åŸå§‹æ–‡æœ¬èˆ‡ metadataï¼‰\n",
        "peek_data = vectordb._collection.get(limit=1)\n",
        "\n",
        "for i in range(len(peek_data[\"documents\"])):\n",
        "    print(f\"\\n--- Entry {i+1} ---\")\n",
        "    print(\"Document ID:\", peek_data[\"ids\"][i])\n",
        "    print(\"Document Text:\", peek_data[\"documents\"][i])\n",
        "    print(\"Metadata:\", peek_data[\"metadatas\"][i])\n",
        "\n",
        "peek_data = vectordb._collection.get(limit=1, offset=vectordb._collection.count() - 1)\n",
        "\n",
        "# é¡¯ç¤ºè©²ç­†å…§å®¹\n",
        "for i in range(len(peek_data[\"documents\"])):\n",
        "    print(f\"\\n--- Last Entry ---\")\n",
        "    print(\"Document ID:\", peek_data[\"ids\"][i])\n",
        "    print(\"Document Text:\", peek_data[\"documents\"][i])\n",
        "    print(\"Metadata:\", peek_data[\"metadatas\"][i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check CU log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… CU initialization successful (all indicators present).\n",
            "ğŸŸ¢ No configuration issue detected, no correction needed.\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            " CU initialization success\n"
          ]
        }
      ],
      "source": [
        "syntax_error_pattern = re.compile(r'\\[LIBCONFIG\\] file (?P<filepath>.+?) - line (?P<linenum>\\d+): syntax error')\n",
        "success_keywords = [\n",
        "    \"Send NGSetupRequest to AMF\",\n",
        "    \"Received NGSetupResponse from AMF\",\n",
        "    \"Starting F1AP at CU\"\n",
        "]\n",
        "\n",
        "matched_case = None\n",
        "found_by_syntax_error = False\n",
        "\n",
        "\n",
        "if not Path(cu_log_file).exists():\n",
        "    raise FileNotFoundError(f\"Log file not found: {cu_log_file}\")\n",
        "if not Path(debug_yaml_path).exists():\n",
        "    raise FileNotFoundError(f\"Debug YAML not found: {debug_yaml_path}\")\n",
        "\n",
        "# Read debug.yaml\n",
        "with open(debug_yaml_path, 'r', encoding='utf-8') as f:\n",
        "    debug_data = yaml.safe_load(f)\n",
        "\n",
        "# Organize (log_snippet, stage) pairs\n",
        "target_entries = []\n",
        "found_results = []\n",
        "found_set = set()\n",
        "all_lines = []\n",
        "cu_query = \"\"\n",
        "\n",
        "for item in debug_data:\n",
        "    if 'log_snippet' in item:\n",
        "        raw_snippet = item['log_snippet']\n",
        "        stage = item.get('stage', 'unknown')\n",
        "\n",
        "        # å¦‚æœæ˜¯ listï¼ˆå¤šå€‹ snippetï¼‰\n",
        "        if isinstance(raw_snippet, list):\n",
        "            for s in raw_snippet:\n",
        "                target_entries.append((s.strip(), stage))\n",
        "        # å¦‚æœæ˜¯å­—ä¸²ä¸”åŒ…å«åˆ†è™Ÿï¼ˆå¤šæ®µ snippetï¼‰\n",
        "        elif isinstance(raw_snippet, str) and \";\" in raw_snippet:\n",
        "            parts = [s.strip() for s in raw_snippet.split(\";\")]\n",
        "            for p in parts:\n",
        "                target_entries.append((p, stage))\n",
        "        # å–®ä¸€å­—ä¸² snippet\n",
        "        elif isinstance(raw_snippet, str):\n",
        "            target_entries.append((raw_snippet.strip(), stage))\n",
        "\n",
        "\n",
        "assert_exit_found = False\n",
        "\n",
        "# æœç´¢ log\n",
        "with open(cu_log_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "    for raw_line in f:\n",
        "        line = clean_text(raw_line)\n",
        "        all_lines.append(line)  # æš«å­˜æ‰€æœ‰ log è¡Œï¼Œä¾›å¾ŒçºŒç¼ºå¤±åˆ¤æ–·ç”¨\n",
        "\n",
        "        # âœ… å¦‚æœåµæ¸¬åˆ° syntax error ä¸¦è¼¸å‡ºéŒ¯èª¤è¡Œ\n",
        "        match = syntax_error_pattern.search(line)\n",
        "        if match:\n",
        "            conf_path_str = match.group(\"filepath\")\n",
        "            line_num = int(match.group(\"linenum\"))\n",
        "            filename = Path(conf_path_str).name\n",
        "            conf_path = current_cu_config_path.parent / filename\n",
        "\n",
        "\n",
        "            if conf_path.exists():\n",
        "                try:\n",
        "                    with open(conf_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as cf:\n",
        "                        lines = cf.readlines()\n",
        "                        if 0 < line_num <= len(lines):\n",
        "                            error_line = lines[line_num - 1].strip()\n",
        "                        else:\n",
        "                            error_line = \"<Line number out of range>\"\n",
        "\n",
        "                        # === ğŸ” é¡¯ç¤ºéŒ¯èª¤è¡Œèˆ‡æª”æ¡ˆè³‡è¨Š ===\n",
        "                        print(\"\\nğŸ›‘ Detected syntax error in config:\")\n",
        "                        print(f\"ğŸ“„ File: {conf_path}\")\n",
        "                        print(f\"ğŸ“ Line {line_num}: {error_line}\")\n",
        "                        print(\"--------------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "                        # === ğŸ§© æ“·å– config key ===\n",
        "                        config_key = extract_config_key(error_line)\n",
        "                        print(f\"ğŸ§© Extracted config key: {config_key}\")\n",
        "\n",
        "                        # === ğŸ§  å»ºç«‹èªæ„ queryï¼ˆå¯ä¾›èªæ„ fallback ä½¿ç”¨ï¼‰ ===\n",
        "                        cu_query = f\"CU failed to start due to `{config_key}` syntax error in configuration file\"\n",
        "                        print(f\"ğŸ§  Constructed Semantic Query: {cu_query}\")\n",
        "\n",
        "                        print(\"--------------------------------------------------------------------------------------------------------------\")\n",
        "                        # === ğŸ” æŸ¥è©¢ç›¸é—œé…ç½®æ¡ˆä¾‹ ===\n",
        "                        results = vectordb.similarity_search(config_key, k=1)\n",
        "                        matched_case = None\n",
        "                        for doc in results:\n",
        "                            rc_raw = doc.metadata.get('related_config', [])\n",
        "                            rc_list = rc_raw if isinstance(rc_raw, list) else [rc_raw]\n",
        "\n",
        "                            print(\"ğŸ” Checking document...\")\n",
        "                            print(f\"ğŸ“„ Page Content: {doc.page_content[:100]}...\")  # é¿å…è¼¸å‡ºå¤ªé•·\n",
        "                            print(f\"ğŸ“‘ related_config: {rc_list}\")\n",
        "                            print(\"------\")\n",
        "\n",
        "                            if config_key in rc_list:\n",
        "                                matched_case = doc\n",
        "                                found_by_syntax_error = True\n",
        "                                print(\"âœ… Matched related_config!\")\n",
        "                                \n",
        "                                break\n",
        "\n",
        "                        if matched_case:\n",
        "                            print(\"\\n--- âœ… Final Matched Case ---\")\n",
        "                            # print(f\"ğŸ“ Case: {matched_case.page_content}\")\n",
        "                            print(f\"â— Symptom: {matched_case.metadata.get('symptom', '')}\")\n",
        "                            print(f\"ğŸ”§ Related Config: {matched_case.metadata.get('related_config', '')}\")\n",
        "                            # print(f\"ğŸ“Œ Notes:\\n{matched_case.metadata.get('notes', '')}\")\n",
        "                        else:\n",
        "                            print(f\"âŒ No case matched for related_config = {config_key}\")\n",
        "\n",
        "\n",
        "                        \n",
        "                except Exception as e:\n",
        "                    print(f\"âš ï¸ Failed to read config file {conf_path}: {e}\")\n",
        "            else:\n",
        "                print(f\"âŒ Config file not found: {conf_path}\")\n",
        "            continue  # å¯ä»¥é¸æ“‡æ˜¯å¦ç¹¼çºŒè™•ç†å…¶ä»– log è¡Œ\n",
        "        \n",
        "        # âœ… å¦‚æœåµæ¸¬åˆ° Assert_Exit_ ä¸¦è¼¸å‡ºéŒ¯èª¤è¡Œ\n",
        "        if 'Assert_Exit_' in line:\n",
        "            print(f\"âš ï¸ Found Assert_Exit_ log, skipping critical log check.\")\n",
        "            break\n",
        "\n",
        "        # âœ… æ¯”å° debug.yaml ä¸­çš„ snippet\n",
        "        for snippet, stage in target_entries:\n",
        "            snippet_cleaned = clean_text(snippet)\n",
        "            if snippet_cleaned in line:\n",
        "                found_results.append((stage, snippet))\n",
        "                found_set.add(snippet_cleaned)\n",
        "          \n",
        "# âœ… Stage 1: All keywords matched â†’ CU initialization is fully successful\n",
        "if all(any(kw in line for line in all_lines) for kw in success_keywords):\n",
        "    print(\"âœ… CU initialization successful (all indicators present).\")\n",
        "    print(\"ğŸŸ¢ No configuration issue detected, no correction needed.\")\n",
        "    cu_query += \" CU initialization success\"\n",
        "\n",
        "# ğŸŸ¡ Stage 2: Some keywords matched â†’ Possible segmentation fault suspected\n",
        "elif any(any(kw in line for line in all_lines) for kw in success_keywords):\n",
        "    matched_keywords = [kw for kw in success_keywords if any(kw in line for line in all_lines)]\n",
        "    print(\"ğŸŸ¡ CU initialization incomplete: possible segmentation fault.\")\n",
        "    print(f\"ğŸ” Detected partial success indicators: {matched_keywords}\")\n",
        "    if not any(\"Starting F1AP at CU\" in line for line in all_lines):\n",
        "        print(\"F1AP not started â€” possible invalid tr_s_preference setting\")\n",
        "        cu_query += \" CU F1AP not started â€” possible invalid tr_s_preference setting\"\n",
        "\n",
        "# âŒ Stage 3: No success keywords found â†’ CU initialization failed\n",
        "else:\n",
        "    print(\"âŒ CU initialization failed: no success indicators found.\")\n",
        "    cu_query += \"| CU init failure\"\n",
        "\n",
        "print(\"-------------------------------------------------------------------------------------------------------------\")\n",
        "print(cu_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check DU log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/aiml/johnson/Scenario/Scenario_Latest_for_du_testing/input_data/log/97_du_gnb_nr_cellid_v12_log.txt\n",
            "âœ… Matched snippet: Assertion (du_cell->nr_cellid == cu_cell->nr_cellid) failed! in stage du_init\n",
            "ğŸ” Attempting to locate matching YAML debug case...\n",
            "\n",
            "--- âœ… YAML Debug Case Matched by Snippet ---\n",
            "ğŸ©º Symptom: DU crashed due to mismatched nr_cellid with CU\n",
            "ğŸ§© Related Config: ['nr_cellid']\n",
            "ğŸ“ Notes:\n",
            "The DU defines `nr_cellid = 2147483648` (0x80000000), which exceeds the signed 32-bit integer range.\n",
            "\n",
            "When the CU parses this value, it may interpret it as `-2147483648`, causing a mismatch during F1 Setup handling.\n",
            "\n",
            "This triggers an assertion failure and causes the DU softmodem to crash during initialization.\n",
            "\n",
            "-  Fix:\n",
            "- Set `nr_cellid` to a safe and valid positive value like:\n",
            "  ```c\n",
            "  nr_cellid = 1;\n",
            "  ```\n",
            "\n",
            "- Best Practice:\n",
            "- Always ensure both DU and CU explicitly define the same `nr_cellid`.\n",
            "- Avoid borderline values like `2147483648` that may cause signed overflow.\n",
            "\n",
            "âŒ DU initialization failed: no success indicators found.\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            " DU symptom: DU crashed due to mismatched nr_cellid with CU| DU init failure\n"
          ]
        }
      ],
      "source": [
        "syntax_error_pattern = re.compile(r'\\[LIBCONFIG\\] file (?P<filepath>.+?) - line (?P<linenum>\\d+): syntax error')\n",
        "success_keywords = [\n",
        "    \"[NR_MAC]   Frame.Slot 128.0\",\n",
        "    \"[NR_MAC]   Frame.Slot 256.0\",\n",
        "]\n",
        "\n",
        "matched_case = None\n",
        "found_by_syntax_error = False\n",
        "\n",
        "\n",
        "if not Path(du_log_file).exists():\n",
        "    raise FileNotFoundError(f\"Log file not found: {du_log_file}\")\n",
        "if not Path(debug_yaml_path).exists():\n",
        "    raise FileNotFoundError(f\"Debug YAML not found: {debug_yaml_path}\")\n",
        "\n",
        "print(du_log_file)\n",
        "# Read debug.yaml\n",
        "with open(debug_yaml_path, 'r', encoding='utf-8') as f:\n",
        "    debug_data = yaml.safe_load(f)\n",
        "\n",
        "# Organize (log_snippet, stage) pairs\n",
        "target_entries = []\n",
        "found_results = []\n",
        "found_set = set()\n",
        "all_lines = []\n",
        "du_query = \"\"\n",
        " \n",
        "for item in debug_data:\n",
        "    if 'log_snippet' in item:\n",
        "        raw_snippet = item['log_snippet']\n",
        "        stage = item.get('stage', 'unknown')\n",
        "\n",
        "        # å¦‚æœæ˜¯ listï¼ˆå¤šå€‹ snippetï¼‰\n",
        "        if isinstance(raw_snippet, list):\n",
        "            for s in raw_snippet:\n",
        "                target_entries.append((s.strip(), stage))\n",
        "        # å¦‚æœæ˜¯å­—ä¸²ä¸”åŒ…å«åˆ†è™Ÿï¼ˆå¤šæ®µ snippetï¼‰\n",
        "        elif isinstance(raw_snippet, str) and \";\" in raw_snippet:\n",
        "            parts = [s.strip() for s in raw_snippet.split(\";\")]\n",
        "            for p in parts:\n",
        "                target_entries.append((p, stage))\n",
        "        # å–®ä¸€å­—ä¸² snippet\n",
        "        elif isinstance(raw_snippet, str):\n",
        "            target_entries.append((raw_snippet.strip(), stage))\n",
        "\n",
        "\n",
        "assert_exit_found = False\n",
        "matched_by_snippet = False  \n",
        "\n",
        "# æœç´¢ log\n",
        "with open(du_log_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "    for raw_line in f:\n",
        "        line = clean_text(raw_line)\n",
        "        all_lines.append(line)  # æš«å­˜æ‰€æœ‰ log è¡Œï¼Œä¾›å¾ŒçºŒç¼ºå¤±åˆ¤æ–·ç”¨\n",
        "\n",
        "        # âœ… å¦‚æœåµæ¸¬åˆ° syntax error ä¸¦è¼¸å‡ºéŒ¯èª¤è¡Œ\n",
        "        match = syntax_error_pattern.search(line)\n",
        "        if match:\n",
        "            conf_path_str = match.group(\"filepath\")\n",
        "            line_num = int(match.group(\"linenum\"))\n",
        "            filename = Path(conf_path_str).name\n",
        "            conf_path = current_cu_config_path.parent / filename\n",
        "            if conf_path.exists():\n",
        "                try:\n",
        "                    with open(conf_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as cf:\n",
        "                        lines = cf.readlines()\n",
        "                        if 0 < line_num <= len(lines):\n",
        "                            error_line = lines[line_num - 1].strip()\n",
        "                        else:\n",
        "                            error_line = \"<Line number out of range>\"\n",
        "\n",
        "                        # === ğŸ” é¡¯ç¤ºéŒ¯èª¤è¡Œèˆ‡æª”æ¡ˆè³‡è¨Š ===\n",
        "                        print(\"\\nğŸ›‘ Detected syntax error in config:\")\n",
        "                        print(f\"ğŸ“„ File: {conf_path}\")\n",
        "                        print(f\"ğŸ“ Line {line_num}: {error_line}\")\n",
        "                        print(\"--------------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "                        # === ğŸ§© æ“·å– config key ===\n",
        "                        config_key = extract_config_key(error_line)\n",
        "                        print(f\"ğŸ§© Extracted config key: {config_key}\")\n",
        "\n",
        "                        # === ğŸ§  å»ºç«‹èªæ„ queryï¼ˆå¯ä¾›èªæ„ fallback ä½¿ç”¨ï¼‰ ===\n",
        "                        du_query = f\"dU failed to start due to `{config_key}` syntax error in configuration file\"\n",
        "                        print(f\"ğŸ§  Constructed Semantic Query: {du_query}\")\n",
        "\n",
        "                        print(\"--------------------------------------------------------------------------------------------------------------\")\n",
        "                        # === ğŸ” æŸ¥è©¢ç›¸é—œé…ç½®æ¡ˆä¾‹ ===\n",
        "                        results = vectordb.similarity_search(config_key, k=1)\n",
        "                        matched_case = None\n",
        "                        for doc in results:\n",
        "                            rc_raw = doc.metadata.get('related_config', [])\n",
        "                            rc_list = rc_raw if isinstance(rc_raw, list) else [rc_raw]\n",
        "\n",
        "                            print(\"ğŸ” Checking document...\")\n",
        "                            print(f\"ğŸ“„ Page Content: {doc.page_content[:100]}...\")  # é¿å…è¼¸å‡ºå¤ªé•·\n",
        "                            print(f\"ğŸ“‘ related_config: {rc_list}\")\n",
        "                            print(\"------\")\n",
        "\n",
        "                            if config_key in rc_list:\n",
        "                                matched_case = doc\n",
        "                                found_by_syntax_error = True\n",
        "                                print(\"âœ… Matched related_config!\")\n",
        "                                \n",
        "                                break\n",
        "\n",
        "                        if matched_case:\n",
        "                            print(\"\\n--- âœ… Final Matched Case ---\")\n",
        "                            # print(f\"ğŸ“ Case: {matched_case.page_content}\")\n",
        "                            print(f\"â— Symptom: {matched_case.metadata.get('symptom', '')}\")\n",
        "                            print(f\"ğŸ”§ Related Config: {matched_case.metadata.get('related_config', '')}\")\n",
        "                            # print(f\"ğŸ“Œ Notes:\\n{matched_case.metadata.get('notes', '')}\")\n",
        "                        else:\n",
        "                            print(f\"âŒ No case matched for related_config = {config_key}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"âš ï¸ Failed to read config file {conf_path}: {e}\")\n",
        "            else:\n",
        "                print(f\"âŒ Config file not found: {conf_path}\")\n",
        "            continue  # å¯ä»¥é¸æ“‡æ˜¯å¦ç¹¼çºŒè™•ç†å…¶ä»– log è¡Œ\n",
        "\n",
        "\n",
        "        # âœ… åƒ…æ¯”å° debug.yaml ä¸­ stage ç‚º du_init çš„ log_snippet\n",
        "        for item in debug_data:\n",
        "            if item.get(\"stage\") != \"du_init\":\n",
        "                continue  # â›” è·³éé du_init çš„æ¢ç›®\n",
        "\n",
        "            stage = item.get(\"stage\", \"unknown\")\n",
        "            snippets = item.get(\"log_snippet\", [])\n",
        "\n",
        "            for snippet in snippets:\n",
        "                snippet_cleaned = clean_text(snippet)\n",
        "                if snippet_cleaned in line:\n",
        "                    found_results.append((stage, snippet))\n",
        "                    found_set.add(snippet_cleaned)\n",
        "                    matched_by_snippet = True\n",
        "                    print(f\"âœ… Matched snippet: {snippet_cleaned} in stage {stage}\")\n",
        "                    break\n",
        "\n",
        "        if matched_by_snippet:\n",
        "            break\n",
        "# å¦‚æœæ²’æœ‰æ‰¾åˆ°ä»»ä½• snippet åŒ¹é…ï¼Œå‰‡è¼¸å‡ºè­¦å‘Š\n",
        "if matched_by_snippet:\n",
        "    print(\"ğŸ” Attempting to locate matching YAML debug case...\")\n",
        "\n",
        "    for item in debug_data:\n",
        "        raw_snippet = item.get('log_snippet', \"\")\n",
        "        snippet_list = []\n",
        "        \n",
        "        # çµ±ä¸€è½‰ç‚º list è™•ç†\n",
        "        if isinstance(raw_snippet, list):\n",
        "            snippet_list = raw_snippet\n",
        "        elif isinstance(raw_snippet, str) and \";\" in raw_snippet:\n",
        "            snippet_list = [s.strip() for s in raw_snippet.split(\";\")]\n",
        "        elif isinstance(raw_snippet, str):\n",
        "            snippet_list = [raw_snippet.strip()]\n",
        "\n",
        "        # å˜—è©¦æ¯”å°å…¶ä¸­ä¸€æ®µ\n",
        "        for s in snippet_list:\n",
        "            if clean_text(s) in found_set:\n",
        "                matched_case = item  # æˆåŠŸæ¯”å°çš„ YAML æ•´æ®µå…§å®¹\n",
        "                du_matched_content = f\"Stage: {item.get('stage')}\\nSymptom: {item.get('symptom')}\\n\"\n",
        "                du_matched_related_config = item.get('related_config', [])\n",
        "                du_matched_notes = item.get('notes', '')\n",
        "                \n",
        "                print(\"\\n--- âœ… YAML Debug Case Matched by Snippet ---\")\n",
        "                print(f\"ğŸ©º Symptom: {item.get('symptom')}\")\n",
        "                du_query += f\" DU symptom: {item.get('symptom', '')}\"\n",
        "                print(f\"ğŸ§© Related Config: {du_matched_related_config}\")\n",
        "                print(f\"ğŸ“ Notes:\\n{du_matched_notes}\")\n",
        "                break\n",
        "        if matched_case:\n",
        "            break\n",
        "if not found_set:\n",
        "    print(\"âš ï¸ No matching snippets found in DU log.\")\n",
        "        \n",
        "\n",
        "          \n",
        "# âœ… Stage 1: All keywords matched â†’ DU initialization is fully successful\n",
        "if all(any(kw in line for line in all_lines) for kw in success_keywords):\n",
        "    print(\"âœ… DU initialization successful (all indicators present).\")\n",
        "    print(\"ğŸŸ¢ No configuration issue detected, no correction needed.\")\n",
        "    du_query += \" DU initialization success\"\n",
        "else:\n",
        "    print(\"âŒ DU initialization failed: no success indicators found.\")\n",
        "    du_query += \"| DU init failure\"\n",
        "\n",
        "print(\"-------------------------------------------------------------------------------------------------------------\")\n",
        "print(du_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- CU Matched Case ---\n",
            "Symptom: CU initialization success\n",
            "Related Config: \n",
            "Notes:,The CU started successfully and no issues were detected in the configuration file.\n",
            "All required parameters are correctly set.\n",
            "No changes are required at this stage.\n",
            "\n",
            "\n",
            "--- DU Matched Case ---\n",
            "Symptom: DU crashed due to mismatched nr_cellid with CU\n",
            "Related Config: nr_cellid\n",
            "Notes:,The DU defines `nr_cellid = 2147483648` (0x80000000), which exceeds the signed 32-bit integer range.\n",
            "\n",
            "When the CU parses this value, it may interpret it as `-2147483648`, causing a mismatch during F1 Setup handling.\n",
            "\n",
            "This triggers an assertion failure and causes the DU softmodem to crash during initialization.\n",
            "\n",
            "-  Fix:\n",
            "- Set `nr_cellid` to a safe and valid positive value like:\n",
            "  ```c\n",
            "  nr_cellid = 1;\n",
            "  ```\n",
            "\n",
            "- Best Practice:\n",
            "- Always ensure both DU and CU explicitly define the same `nr_cellid`.\n",
            "- Avoid borderline values like `2147483648` that may cause signed overflow.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if found_by_syntax_error:\n",
        "    if matched_case:\n",
        "        matched_content = matched_case.page_content\n",
        "        matched_symptom = matched_case.metadata.get(\"symptom\", \"\")\n",
        "        matched_related_config = matched_case.metadata.get(\"related_config\", \"\")\n",
        "        matched_Notes = matched_case.metadata.get(\"notes\", \"\")\n",
        "\n",
        "        # è¼¸å‡ºçµæœ\n",
        "        print(\"\\n--- Matched Case ---\")\n",
        "        # print(f\"Case: {matched_content}\")\n",
        "        # print(\"==============\")\n",
        "        print(f\"Symptom: {matched_symptom}\")\n",
        "        print(f\"Related Config: {matched_related_config}\")\n",
        "        print(f\"Notes:,{matched_Notes}\")\n",
        "    else:\n",
        "        print(\"âŒ No case matched for related_config = {config_key}\")\n",
        "    \n",
        "else:\n",
        "    cu_results = vectordb.similarity_search(cu_query, k=2)\n",
        "    cu_matched_case = cu_results[0]\n",
        "    cu_matched_content = cu_matched_case.page_content\n",
        "    cu_matched_symptom = cu_matched_case.metadata.get(\"symptom\", \"\")\n",
        "    cu_matched_related_config = cu_matched_case.metadata.get(\"related_config\", \"\")\n",
        "    cu_matched_Notes = cu_matched_case.metadata.get(\"notes\", \"\")\n",
        "    # è¼¸å‡ºçµæœ\n",
        "    print(\"\\n--- CU Matched Case ---\")\n",
        "    print(f\"Symptom: {cu_matched_symptom}\")\n",
        "    print(f\"Related Config: {cu_matched_related_config}\")\n",
        "    print(f\"Notes:,{cu_matched_Notes}\")\n",
        "\n",
        "    du_results = vectordb.similarity_search(du_query, k=2)\n",
        "    du_matched_case = du_results[0]\n",
        "    du_matched_content = du_matched_case.page_content\n",
        "    du_matched_symptom = du_matched_case.metadata.get(\"symptom\", \"\")\n",
        "    du_matched_related_config = du_matched_case.metadata.get(\"related_config\", \"\")\n",
        "    du_matched_Notes = du_matched_case.metadata.get(\"notes\", \"\")\n",
        "    print(\"\\n--- DU Matched Case ---\")\n",
        "    print(f\"Symptom: {du_matched_symptom}\")\n",
        "    print(f\"Related Config: {du_matched_related_config}\")\n",
        "    print(f\"Notes:,{du_matched_Notes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prompt conf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(current_cu_config_json_path, \"r\") as f:\n",
        "    config_cu_segments_context = json.load(f)\n",
        "with open(current_du_config_json_path, \"r\") as f:\n",
        "    config_du_segments_context = json.load(f)\n",
        "# with open(current_ru_config_json_path, \"r\") as f:\n",
        "#     config_ru_segments_context = json.load(f)\n",
        "\n",
        "\n",
        "with open(reference_context_path, \"r\") as f:\n",
        "    reference_context = f.read()\n",
        "\n",
        "# RAG prompt_template\n",
        "rag_prompt_template = f\"\"\"\n",
        "You are a 5G network expert. Your job is to revise configuration files based on observed network issues and debug knowledge.\n",
        "\n",
        "Issue Description:\n",
        "\"{cu_query}\"\n",
        "\"{du_query}\"\n",
        "\n",
        "Matching cu debug knowledge:\n",
        "{cu_matched_case.metadata[\"symptom\"]}\n",
        "{cu_matched_case.metadata[\"notes\"] if cu_matched_case.metadata[\"notes\"] else \"\"}\n",
        "Relevant parameters: {cu_matched_case.metadata[\"related_config\"]}\n",
        "\n",
        "Matching du debug knowledge:\n",
        "{du_matched_case.metadata[\"symptom\"]}\n",
        "{du_matched_case.metadata[\"notes\"] if du_matched_case.metadata[\"notes\"] else \"\"}\n",
        "Relevant parameters: {du_matched_case.metadata[\"related_config\"]}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Reference Device Address Table (external reference file):\n",
        "{reference_context}\n",
        "\n",
        "Current CU configuration block:\n",
        "{config_cu_segments_context}\n",
        "{config_du_segments_context}\n",
        "\n",
        "Please revise the configuration using correct addresses from the reference. Output only the revised config section.\n",
        "\n",
        "Return a list of JSON objects with the following structure:\n",
        "\n",
        "```json\n",
        "[\n",
        "  {{\n",
        "    \"label\": \"parameter_name\",\n",
        "    \"content\": \"parameter_name = (...);\",\n",
        "    \"reference_reason\": \"Explain the value based on reference_context (e.g., matches expected IP or MAC). If no relevant info is found, respond with: 'No relevant information found in reference_context.'\",    \n",
        "    \"model_reason\": \"Additional expert analysis in 1-2 sentences explaining why this change is necessary, beneficial, or resolves a network issue.\"\n",
        "    \"target\": \"CU\" or \"DU\" or \"RU\" or \"FH\"\n",
        "  }},\n",
        "  ...\n",
        "]\n",
        "```\n",
        "\n",
        "- Only include parameters listed in 'Relevant parameters'.\n",
        "- Do not include any explanation outside of the JSON structure.\n",
        "- Keep \"reference_reason\" based on the reference table.\n",
        "- Derive \"model_reason\" from your own technical reasoning.\n",
        "- Set the \"target\" field based on the location of the parameter: \"CU\" for CU config, \"DU\" for DU config, \"RU\" for RU config, and \"FH\" for FH config.\n",
        "- If multiple configuration problems exist at the same time, return multiple JSON objects â€” one for each necessary change.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "none_rag_prompt_template = f\"\"\"\n",
        "You are a 5G network expert. Your job is to revise configuration files based on observed network issues.\n",
        "\n",
        "Issue Description:\n",
        "\"{cu_query}\"\n",
        "\"{du_query}\"\n",
        "\n",
        "Current configuration block:\n",
        "{config_cu_segments_context}\n",
        "{config_du_segments_context}\n",
        "\n",
        "Please revise the configuration to resolve the described issue based on your technical expertise.\n",
        "\n",
        "Return a list of JSON objects with the following structure:\n",
        "\n",
        "```json\n",
        "[\n",
        "  {{\n",
        "    \"label\": \"parameter_name\",\n",
        "    \"content\": \"parameter_name = (...);\",\n",
        "    \"model_reason\": \"Technical explanation in 1-2 sentences explaining why this change is necessary, beneficial, or resolves the network issue.\"\n",
        "  }},\n",
        "  ...\n",
        "]\n",
        "```\n",
        "\n",
        "- Only revise parameters that are necessary to resolve the issue.\n",
        "- If no changes are needed, return an empty list: []\n",
        "- Strictly output only valid JSON without any additional text or explanation.\n",
        "\"\"\"\n",
        "\n",
        "reason_output_dir = \"Reason\"\n",
        "os.makedirs(reason_output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "def save_json(filename, data):\n",
        "    with open(os.path.join(reason_output_dir, filename), \"w\", encoding='utf-8') as f:\n",
        "        json.dump(data, f, indent=2, ensure_ascii=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… No inference needed: CU initialization is successful.\n",
            "âœ… [CU] Updated file: /home/aiml/johnson/Scenario/Scenario_Latest_for_du_testing/output_data/0_cu_gnb_original_modification.conf\n",
            "âœ… Diff saved to: /home/aiml/johnson/Scenario/Scenario_Latest_for_du_testing/output_data/0_cu_gnb_original_diff.log\n",
            "\n",
            "ğŸ“ [CU] SFT data saved to: /home/aiml/johnson/Scenario/Scenario_Latest_for_du_testing/output_data/0_cu_gnb_original_modification_CU_sft.json\n",
            "âœ… Renamed SFT file to: /home/aiml/johnson/Scenario/Scenario_Latest_for_du_testing/output_data/pass_0_cu_gnb_original_modification_CU_sft.json\n",
            "LLM Suggested Revisionsï¼š\n",
            "\n",
            "```json\n",
            "[\n",
            "  {\n",
            "    \"label\": \"nr_cellid\",\n",
            "    \"content\": \"nr_cellid = 1;\",\n",
            "    \"reference_reason\": \"No relevant information found in reference_context.\",\n",
            "    \"model_reason\": \"The DU crashed because nr_cellid was out of the 32-bit signed integer range. Setting it to 1 resolves the crash and allows successful DU initialization.\",\n",
            "    \"target\": \"DU\"\n",
            "  }\n",
            "]\n",
            "```\n",
            "========= Suggestions =========\n",
            "[{'label': 'nr_cellid', 'content': 'nr_cellid = 1;', 'reference_reason': 'No relevant information found in reference_context.', 'model_reason': 'The DU crashed because nr_cellid was out of the 32-bit signed integer range. Setting it to 1 resolves the crash and allows successful DU initialization.', 'target': 'DU'}]\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "cu_skip_processing = False\n",
        "du_skip_processing = False\n",
        "\n",
        "if cu_query.strip().lower() == \"cu initialization success\":\n",
        "    print(\"âœ… No inference needed: CU initialization is successful.\")\n",
        "\n",
        "    cu_suggestions = [\n",
        "        {\n",
        "            \"label\": \"CU Initialization\",\n",
        "            \"reference_reason\": \"\"\n",
        "        }\n",
        "    ]\n",
        "    change_log = [\n",
        "        (\"CU Initialization\", None, None, \"CU started successfully. No revision needed.\")\n",
        "    ]\n",
        "\n",
        "    dummy_content = \"// No changes needed. CU started successfully.\\n\"\n",
        "\n",
        "    # ç”¢å‡ºåŸå§‹ä¿®æ”¹çµæœèˆ‡ SFT æª”æ¡ˆ\n",
        "    save_modified_config(dummy_content, rag_after_cu_conf_path, \"CU\")\n",
        "    compare_conf_files(current_cu_config_path, rag_after_cu_conf_path, cu_diff_log_path)\n",
        "    save_sft_data(change_log, rag_after_cu_conf_path, \"CU\", cu_suggestions, current_cu_config_path)\n",
        "\n",
        "    # â• é‡æ–°å‘½åç‚º pass_ é–‹é ­çš„æª”æ¡ˆ\n",
        "    base_dir = os.path.dirname(rag_after_cu_conf_path)\n",
        "    base_name = os.path.basename(rag_after_cu_conf_path)\n",
        "    sft_name = base_name.replace(\".conf\", \"_CU_sft.json\")  # æ ¹æ“šä½ ç¿’æ…£çš„å‘½åæ–¹å¼\n",
        "    sft_path = os.path.join(base_dir, sft_name)\n",
        "\n",
        "    if os.path.exists(sft_path):\n",
        "        new_sft_path = os.path.join(base_dir, f\"pass_{sft_name}\")\n",
        "        os.rename(sft_path, new_sft_path)\n",
        "        print(f\"âœ… Renamed SFT file to: {new_sft_path}\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ SFT file not found for renaming: {sft_path}\")\n",
        "\n",
        "    cu_skip_processing = True\n",
        "\n",
        "if du_query.strip().lower() == \"du initialization success\":\n",
        "    print(\"âœ… No inference needed: DU initialization is successful.\")\n",
        "\n",
        "    du_suggestions = [\n",
        "        {\n",
        "            \"label\": \"DU Initialization\",\n",
        "            \"reference_reason\": \"\"\n",
        "        }\n",
        "    ]\n",
        "    change_log = [\n",
        "        (\"DU Initialization\", None, None, \"DU started successfully. No revision needed.\")\n",
        "    ]\n",
        "\n",
        "    dummy_content = \"// No changes needed. DU started successfully.\\n\"\n",
        "\n",
        "    # ç”¢å‡ºåŸå§‹ä¿®æ”¹çµæœèˆ‡ SFT æª”æ¡ˆ\n",
        "    save_modified_config(dummy_content, rag_after_du_conf_path, \"DU\")\n",
        "    compare_conf_files(current_du_config_path, rag_after_du_conf_path, du_diff_log_path)\n",
        "    save_sft_data(change_log, rag_after_du_conf_path, \"DU\", du_suggestions, current_du_config_path)\n",
        "\n",
        "    # â• é‡æ–°å‘½åç‚º pass_ é–‹é ­çš„æª”æ¡ˆ\n",
        "    base_dir = os.path.dirname(rag_after_du_conf_path)\n",
        "    base_name = os.path.basename(rag_after_du_conf_path)\n",
        "    sft_name = base_name.replace(\".conf\", \"_DU_sft.json\")  # æ ¹æ“šä½ ç¿’æ…£çš„å‘½åæ–¹å¼\n",
        "    sft_path = os.path.join(base_dir, sft_name)\n",
        "\n",
        "    if os.path.exists(sft_path):\n",
        "        new_sft_path = os.path.join(base_dir, f\"pass_{sft_name}\")\n",
        "        os.rename(sft_path, new_sft_path)\n",
        "        print(f\"âœ… Renamed SFT file to: {new_sft_path}\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ SFT file not found for renaming: {sft_path}\")\n",
        "\n",
        "    du_skip_processing = True\n",
        "# else:\n",
        "#     client = OpenAI(\n",
        "#       base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "#       api_key = \"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\"\n",
        "#     )\n",
        "\n",
        "#     response = client.chat.completions.create(\n",
        "#         model=\"meta/llama-3.3-70b-instruct\",\n",
        "#         messages=[\n",
        "#             {\"role\": \"user\", \"content\": rag_prompt_template}\n",
        "#         ],\n",
        "#         temperature=0.2,\n",
        "#         top_p=0.7,\n",
        "#         max_tokens=1024,\n",
        "#         stream=False\n",
        "#     )\n",
        "#     rag_response_text = response.choices[0].message.content\n",
        "#     print(\"LLM Suggested Revisionsï¼š\\n\")\n",
        "#     print(\"RAG Response:\\n\", rag_response_text)\n",
        "\n",
        "\n",
        "#     rag_llm_suggestions = parse_llm_response(rag_response_text)\n",
        "#     print(\"========= Suggestions =========\")\n",
        "#     print(rag_llm_suggestions)\n",
        "\n",
        "\n",
        "\n",
        "#     save_json(f\"{matched_related_config}_rag.json\", rag_llm_suggestions)\n",
        "#     # save_json(f\"{matched_related_config}_none_rag.json\", none_rag_llm_suggestions)\n",
        "\n",
        "else:\n",
        "    genai.configure(api_key=\"AIzaSyBqqRkGvIkAJUZ5MgYcvxw4t3Lx12D4rWU\") #set your API key here\n",
        "    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "    rag_response = model.generate_content(rag_prompt_template)                                # Gemini API\n",
        "    # LLM Suggested Revisions\n",
        "    print(\"LLM Suggested Revisionsï¼š\\n\")\n",
        "    print(rag_response.text)\n",
        "\n",
        "    rag_llm_suggestions = parse_llm_response(rag_response.text)\n",
        "    print(\"========= Suggestions =========\")\n",
        "    print(rag_llm_suggestions)\n",
        "\n",
        "\n",
        "    save_json(f\"{cu_matched_related_config}_rag.json\", rag_llm_suggestions)\n",
        "    save_json(f\"{du_matched_related_config}_rag.json\", rag_llm_suggestions)\n",
        "    # save_json(f\"{matched_related_config}_none_rag.json\", none_rag_llm_suggestions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# genai.configure(api_key=\"AIzaSyBqqRkGvIkAJUZ5MgYcvxw4t3Lx12D4rWU\") #set your API key here\n",
        "# model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "# rag_response = model.generate_content(rag_prompt_template)                                # Gemini API\n",
        "# # LLM Suggested Revisions\n",
        "# print(\"LLM Suggested Revisionsï¼š\\n\")\n",
        "# print(rag_response.text)\n",
        "\n",
        "# rag_llm_suggestions = parse_llm_response(rag_response.text)\n",
        "# print(\"========= Suggestions =========\")\n",
        "# print(rag_llm_suggestions)\n",
        "\n",
        "\n",
        "\n",
        "# save_json(f\"{matched_related_config}_rag.json\", rag_llm_suggestions)\n",
        "# # save_json(f\"{matched_related_config}_none_rag.json\", none_rag_llm_suggestions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True False\n",
            "CU Suggestions:\n",
            "[Output error suppressed]\n",
            "ğŸ“„ No LLM suggestions for CU.\n",
            "DU Suggestions:\n",
            "[Output error suppressed]\n",
            "âœ… [DU] Updated file: /home/aiml/johnson/Scenario/Scenario_Latest_for_du_testing/output_data/97_du_gnb_nr_cellid_v12_modification.conf\n",
            "ğŸ› ï¸ [DU] Modified parameters:\n",
            " - nr_cellid\n",
            "âœ… [DU] Updated file: /home/aiml/johnson/Scenario/Scenario_Latest_for_du_testing/output_data/97_du_gnb_nr_cellid_v12_modification.conf\n",
            "âœ… Diff saved to: /home/aiml/johnson/Scenario/Scenario_Latest_for_du_testing/output_data/97_du_gnb_nr_cellid_v12_diff.log\n",
            "\n",
            "ğŸ“ [DU] SFT data saved to: /home/aiml/johnson/Scenario/Scenario_Latest_for_du_testing/output_data/97_du_gnb_nr_cellid_v12_modification_DU_sft.json\n"
          ]
        }
      ],
      "source": [
        "print(cu_skip_processing, du_skip_processing)\n",
        "\n",
        "if cu_skip_processing and du_skip_processing:\n",
        "    print(\"âœ… No config processing needed: Both CU and DU initialization are successful.\")\n",
        "\n",
        "    \n",
        "elif cu_skip_processing or du_skip_processing:\n",
        "    cu_suggestions, du_suggestions = split_suggestions_by_target(rag_llm_suggestions)\n",
        "\n",
        "    safe_print(\"CU Suggestions:\")\n",
        "    safe_print(cu_suggestions)\n",
        "    process_config_type(\n",
        "        config_type=\"CU\",\n",
        "        suggestions=cu_suggestions,\n",
        "        current_path=current_cu_config_path,\n",
        "        modified_path=rag_after_cu_conf_path,\n",
        "        diff_log_path=cu_diff_log_path\n",
        "    )\n",
        "\n",
        "    safe_print(\"DU Suggestions:\")\n",
        "    safe_print(du_suggestions)\n",
        "    process_config_type(\n",
        "        config_type=\"DU\",\n",
        "        suggestions=du_suggestions,\n",
        "        current_path=current_du_config_path,\n",
        "        modified_path=rag_after_du_conf_path,\n",
        "        diff_log_path=du_diff_log_path\n",
        "    )\n",
        "else:\n",
        "    print(\"âœ… Skipped config processing due to no needed revisions.\")\n",
        "\n",
        "# process_config_type(\n",
        "#     config_type=\"DU\",\n",
        "#     suggestions=du_suggestions,\n",
        "#     current_path=current_du_config_path,\n",
        "#     modified_path=rag_after_du_conf_path,\n",
        "#     diff_log_path=\"/home/aiml/johnson/Scenario/Scenario_For_testing/DU/conf/du_diff_log.txt\"\n",
        "# )\n",
        "\n",
        "# process_config_type(\n",
        "#     config_type=\"RU\",\n",
        "#     suggestions=du_suggestions,\n",
        "#     current_path=current_ru_config_path,\n",
        "#     modified_path=rag_after_ru_conf_path,\n",
        "#     diff_log_path=\"/home/aiml/johnson/Scenario/Scenario_For_testing/DU/conf/du_diff_log.txt\"\n",
        "# )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
